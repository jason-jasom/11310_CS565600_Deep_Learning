{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rorKh0jaYr5W"
   },
   "source": [
    "# **Lab11-1: Convolution Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-hLxtIcYtER"
   },
   "source": [
    "110062209 簡晟棋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkaYQ2MERFDb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, datasets, layers, models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRC1Xbb4iBQb"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "if not os.path.exists(\"lab11_1_lib.py\"):\n",
    "    urllib.request.urlretrieve(\"https://nthu-datalab.github.io/ml/labs/11-1_CNN/lab11_1_lib.py\", \"lab11_1_lib.py\")\n",
    "\n",
    "from lab11_1_lib import draw_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wQyJz7pfsrm",
    "outputId": "ab55acbb-b15e-4eda-d350-b5553acd8122"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1HncttRdMHeNjde8xQCjQQtTLG8dcaTJx\n",
    "!unzip -qq -u oregon_wildlife.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Te622KBRNQk",
    "outputId": "c0fbb6ca-604f-4c82-82a2-0992ba364014"
   },
   "outputs": [],
   "source": [
    "# You need to download the prepared data and unzip the file in current path('./')\n",
    "data_root = pathlib.Path('./oregon_wildlife')\n",
    "\n",
    "# print the subfolders.\n",
    "print('classes:')\n",
    "for item in data_root.iterdir():\n",
    "    print(item)\n",
    "\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "all_image_paths = shuffle(all_image_paths, random_state=1)\n",
    "all_image_paths = [path for path in all_image_paths if path[-3:] not in ('gif','bmp')]\n",
    "image_count = len(all_image_paths)\n",
    "print('\\ntotal img num:', image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "ykOO-MjQWJPG",
    "outputId": "c021c897-77ee-4b69-abe8-a4ecd79ffdb0"
   },
   "outputs": [],
   "source": [
    "# random showing 3 iamges for you\n",
    "for n in range(3):\n",
    "    image_path = random.choice(all_image_paths)\n",
    "    display.display(display.Image(image_path, width=200, height=200))\n",
    "    print(image_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHvRYm_7WMht",
    "outputId": "2b2cd4b9-4c02-41f8-a937-12f727afd862"
   },
   "outputs": [],
   "source": [
    "# get the label\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "# total label\n",
    "n_classes = len(label_names)\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZczfbGxWOmW",
    "outputId": "780a2ca6-b355-4f1e-d07f-ba1bfbb766eb"
   },
   "outputs": [],
   "source": [
    "# get the mapping dict\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "index_to_label = dict((index, name) for index,name in enumerate(label_names))\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLrW7oiMWQs1",
    "outputId": "73f9f35c-f03a-4425-cfa1-359daa50db89"
   },
   "outputs": [],
   "source": [
    "# get the label data\n",
    "all_image_label = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "print(\"First 10 label indices: \", all_image_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wwW8v1CWTH2",
    "outputId": "76ee959b-c56f-4895-8481-1fe322c966f8"
   },
   "outputs": [],
   "source": [
    "# Create training and testing sets using an 80-20 split\n",
    "img_path_train, img_path_test, label_train, label_test = train_test_split(all_image_paths,\n",
    "                                all_image_label,test_size=0.2,random_state=0)\n",
    "print('training data: %d'%(len(img_path_train)))\n",
    "print('testing data: %d'%(len(img_path_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnCT49W1ZgIE"
   },
   "outputs": [],
   "source": [
    "# save (img_path, label) pairs\n",
    "with open('train.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['img_path', 'label'])\n",
    "    for img_path, label in zip(img_path_train, label_train):\n",
    "        writer.writerow([img_path, label])\n",
    "\n",
    "with open('test.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['img_path', 'label'])\n",
    "    for img_path, label in zip(img_path_test, label_test):\n",
    "        writer.writerow([img_path, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYRqEPWVZhqs"
   },
   "outputs": [],
   "source": [
    "# Feel free to change IMAGE_SIZE_CROPPED if using random_crop in your data augmentation process, but make sure the input resize back to (300,300,3) before feed into VGG16\n",
    "IMAGE_SIZE_CROPPED = 224\n",
    "IMAGE_HEIGHT = 300\n",
    "IMAGE_WIDTH = 300\n",
    "IMAGE_DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GloaU4t6ZsdU"
   },
   "outputs": [],
   "source": [
    "# construct a new dataset with time informantion\n",
    "class TimeMeasuredDataset(tf.data.Dataset):\n",
    "    # OUTPUT: (steps, timings, counters, img, label)\n",
    "    OUTPUT_SIGNATURE=(\n",
    "        tf.TensorSpec(shape=(2, 1), dtype=tf.string), # steps: [(\"Open\",), (\"Read\",)]\n",
    "        tf.TensorSpec(shape=(2, 2), dtype=tf.float32), # timings: [(open_enter, open_elapsed), (read_enter, read_elapsed)]\n",
    "        tf.TensorSpec(shape=(2, 3), dtype=tf.int32), # counters: [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, example_idx)]\n",
    "        tf.TensorSpec(shape=(300,300,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32) # label\n",
    "    )\n",
    "\n",
    "    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n",
    "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n",
    "\n",
    "    def _generator(instance_idx, filename, open_file, read_file):\n",
    "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
    "\n",
    "        # Opening the file\n",
    "        open_enter = time.perf_counter()\n",
    "        img_paths, label = open_file(filename)\n",
    "        open_elapsed = time.perf_counter() - open_enter\n",
    "        # ----------------\n",
    "\n",
    "        # Reading the file\n",
    "        for sample_idx in range(len(img_paths)):\n",
    "            # Reading data (line, record) from the file\n",
    "            read_enter = time.perf_counter()\n",
    "            img = read_file(img_paths[sample_idx])\n",
    "            read_elapsed = time.perf_counter() - read_enter\n",
    "\n",
    "            yield (\n",
    "                [(\"Open\",), (\"Read\",)],\n",
    "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
    "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)],\n",
    "                img,\n",
    "                label[sample_idx]\n",
    "            )\n",
    "            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n",
    "\n",
    "\n",
    "    def __new__(cls, filename, open_file, read_file):\n",
    "        def generator_func(instance_idx, filename):\n",
    "            return cls._generator(instance_idx, filename, open_file, read_file)\n",
    "\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            generator_func,\n",
    "            output_signature=cls.OUTPUT_SIGNATURE,\n",
    "            args=(next(cls._INSTANCES_COUNTER), filename)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sanq2Liam1_"
   },
   "outputs": [],
   "source": [
    "def open_file(filename):\n",
    "    rows = pd.read_csv(filename.decode(\"utf-8\"))\n",
    "    img_paths = rows['img_path'].tolist()\n",
    "    label = rows['label'].tolist()\n",
    "    return img_paths, label\n",
    "\n",
    "def read_file(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMAGE_DEPTH)\n",
    "    img = tf.image.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.divide(img,255.0)\n",
    "    return img\n",
    "\n",
    "def dataset_generator_fun_train(*args):\n",
    "    return TimeMeasuredDataset('train.csv', open_file, read_file)\n",
    "\n",
    "def dataset_generator_fun_test(*args):\n",
    "    return TimeMeasuredDataset('test.csv', open_file, read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjohqafozYR2"
   },
   "outputs": [],
   "source": [
    "# feel free to modify these two Settings.\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pIX0lS3ao9V"
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.range(1).flat_map(dataset_generator_fun_train).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_test = tf.data.Dataset.range(1).flat_map(dataset_generator_fun_test).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VbgeCvLaz9v"
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling=None,\n",
    ")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Flatten())\n",
    "top_model.add(layers.Dense(4096, activation='relu'))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(1024, activation='relu'))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "wild_model = tf.keras.Model(inputs=base_model.input, outputs=top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nWXxvmkbP0a"
   },
   "outputs": [],
   "source": [
    "# save the initialization of weights\n",
    "wild_model.save_weights('wild_model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDDqZA9cbRzK"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVYirbqPbTZ0"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = wild_model(image, training=True)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, wild_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, wild_model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = wild_model(image, training=False)\n",
    "    loss = loss_object(label, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g83E51e-b0k1"
   },
   "outputs": [],
   "source": [
    "def timelined_benchmark(dataset_train, dataset_test, EPOCHS):\n",
    "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
    "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
    "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    print(\"start time: \", start_time)\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_enter = time.perf_counter()\n",
    "\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_state()\n",
    "        train_accuracy.reset_state()\n",
    "        test_loss.reset_state()\n",
    "        test_accuracy.reset_state()\n",
    "\n",
    "        tf.print(\"training:\")\n",
    "        for steps, times, values, image, label in tqdm(dataset_train, total=math.floor(len(img_path_train)/BATCH_SIZE)):\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            steps_acc = tf.concat([steps_acc, tf.reshape(steps, (steps.shape[0]*steps.shape[1], 1))], axis=0)\n",
    "            times_acc = tf.concat([times_acc, tf.reshape(times, (times.shape[0]*times.shape[1], 2))], axis=0)\n",
    "            values_acc = tf.concat([values_acc, tf.reshape(values, (values.shape[0]*values.shape[1], 3))], axis=0)\n",
    "\n",
    "            # record training time\n",
    "            train_enter = time.perf_counter()\n",
    "            train_step(image, label)\n",
    "            train_elapsed = time.perf_counter() - train_enter\n",
    "\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            train_time = tf.concat([tf.fill([times.shape[0], 1], train_enter), tf.fill([times.shape[0], 1], train_elapsed)], axis=1) # shape=(times.shape[0], 2)\n",
    "            steps_acc = tf.concat([steps_acc, tf.fill([steps.shape[0], 1], \"Train\")], axis=0)\n",
    "            times_acc = tf.concat([times_acc, train_time], axis=0)\n",
    "            values_acc = tf.concat([values_acc, values[:,-1,:]], axis=0)\n",
    "\n",
    "        tf.print(\"testing:\")\n",
    "        for steps, times, values, image, label in tqdm(dataset_test, total=math.floor(len(img_path_test)/BATCH_SIZE)):\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            steps_acc = tf.concat([steps_acc, tf.reshape(steps, (steps.shape[0]*steps.shape[1], 1))], axis=0)\n",
    "            times_acc = tf.concat([times_acc, tf.reshape(times, (times.shape[0]*times.shape[1], 2))], axis=0)\n",
    "            values_acc = tf.concat([values_acc, tf.reshape(values, (values.shape[0]*values.shape[1], 3))], axis=0)\n",
    "\n",
    "            test_enter = time.perf_counter()\n",
    "            test_step(image, label)\n",
    "            test_elapsed = time.perf_counter() - test_enter\n",
    "\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            test_time = tf.concat([tf.fill([times.shape[0], 1], test_enter), tf.fill([times.shape[0], 1], test_elapsed)], axis=1) # shape=(times.shape[0], 2)\n",
    "            steps_acc = tf.concat([steps_acc, tf.fill([steps.shape[0], 1], \"Test\")], axis=0)\n",
    "            times_acc = tf.concat([times_acc, test_time], axis=0)\n",
    "            values_acc = tf.concat([values_acc, values[:,-1,:]], axis=0)\n",
    "\n",
    "        template = 'Epoch {:0}, Loss: {:.4f}, Accuracy: {:.4f}, test Loss: {:.4f}, test Accuracy: {:.4f}'\n",
    "        tf.print (template.format(epoch+1,\n",
    "                               train_loss.result(),\n",
    "                               train_accuracy.result()*100,\n",
    "                               test_loss.result(),\n",
    "                               test_accuracy.result()*100))\n",
    "\n",
    "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
    "        steps_acc = tf.concat([steps_acc, [[\"Epoch\"]]], axis=0)\n",
    "        times_acc = tf.concat([times_acc, [(epoch_enter, epoch_elapsed)]], axis=0)\n",
    "        values_acc = tf.concat([values_acc, [[-1, epoch, -1]]], axis=0)\n",
    "\n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUpbv17Lb2tU",
    "outputId": "243c9093-1e37-4300-813d-28d9fa82e901"
   },
   "outputs": [],
   "source": [
    "timeline_Naive = timelined_benchmark(dataset_train, dataset_test, EPOCHS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "XzKg4Roeb38M",
    "outputId": "a7d4bb5f-c0b7-465e-91f9-c2ff27012f03"
   },
   "outputs": [],
   "source": [
    "draw_timeline(timeline=timeline_Naive, title=\"Naive\", min_width=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUZio-H4MzTY"
   },
   "source": [
    "1. only data augmentation\n",
    "\n",
    "    training:使用Shuffle ,random flip (left or right), random brightness, random contrast, standardization\n",
    "\n",
    "    testing:使用standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0eCibhfWGRS"
   },
   "outputs": [],
   "source": [
    "## TODO: build `dataset_train_augmentation` and `dataset_test_augmentation` with transformation\n",
    "## Remember to define your own map functions with map_decorator before calling map\n",
    "def map_decorator(func):\n",
    "    def wrapper(steps, times, values, image, label):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(\n",
    "            func,\n",
    "            inp=(steps, times, values, image, label),\n",
    "            Tout=(steps.dtype, times.dtype, values.dtype, image.dtype, tf.float32)\n",
    "        )\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ53UEY0b5-d"
   },
   "outputs": [],
   "source": [
    "\n",
    "@map_decorator\n",
    "def map_fun(steps, times, values, image, label):\n",
    "    # sleep to avoid concurrency issue\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # record the enter time into map_fun()\n",
    "    map_enter = time.perf_counter()\n",
    "\n",
    "    distorted_image = tf.image.random_flip_left_right(image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "    # ----------------\n",
    "\n",
    "    return tf.concat((steps, [[\"Map\"]]), axis=0),\\\n",
    "           tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\\\n",
    "           tf.concat((values, [values[-1]]), axis=0),\\\n",
    "           distorted_image,\\\n",
    "           label\n",
    "\n",
    "@map_decorator\n",
    "def map_fun_test(steps, times, values, image, label):\n",
    "    # sleep to avoid concurrency issue\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # record the enter time into map_fun_test()\n",
    "    map_enter = time.perf_counter()\n",
    "\n",
    "\n",
    "    distorted_image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "    # ----------------\n",
    "\n",
    "    return tf.concat((steps, [[\"Map\"]]), axis=0),\\\n",
    "           tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\\\n",
    "           tf.concat((values, [values[-1]]), axis=0),\\\n",
    "           distorted_image,\\\n",
    "           label\n",
    "dataset_train_augmentation = tf.data.Dataset.range(1).flat_map(dataset_generator_fun_train)\\\n",
    "                                        .map(map_fun)\\\n",
    "                                        .shuffle(BUFFER_SIZE)\\\n",
    "                                        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_test_augmentation = tf.data.Dataset.range(1).flat_map(dataset_generator_fun_test)\\\n",
    "                                        .map(map_fun_test)\\\n",
    "                                        .batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MANuxltVb7gc",
    "outputId": "1bdb07f2-f1ea-487c-956a-b95346174b5f"
   },
   "outputs": [],
   "source": [
    "# load the same initialization of weights and re-train with optimized input pipeline\n",
    "wild_model.load_weights('wild_model.weights.h5')\n",
    "timeline_Augmentation = timelined_benchmark(dataset_train_augmentation, dataset_test_augmentation, EPOCHS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "RUgeJ2gxb81N",
    "outputId": "5a96f741-49e7-4f48-d00d-a8c06c9b90dc"
   },
   "outputs": [],
   "source": [
    "draw_timeline(timeline=timeline_Augmentation, title=\"Augmentation\", min_width=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os12d_GSY2EC"
   },
   "source": [
    "data augmentation雖然耗時上升不少(629->3163)，但也使(train Accuracy,test Accuracy)也從(53%,78%)上升到(88%,91%)，有顯著的改善。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gte6VzgmY4L6"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6AHZyTSNLch"
   },
   "source": [
    "2. data augmentation + optimiztion\n",
    "\n",
    "    data augmentation與上面一樣\n",
    "\n",
    "    optimiztion使用Interleave、Parallel mapping、cache、prefetch與Vectorizing mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDXESwGhb--l"
   },
   "outputs": [],
   "source": [
    "## TODO: build `dataset_train_optimized` and `dataset_test_optimized` with transformation and optimzation\n",
    "## Remember to re-define your own map functions again to make mapping time re-calculated\n",
    "@map_decorator\n",
    "def map_fun_batch(steps, times, values, image, label):\n",
    "    # sleep to avoid concurrency issue\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # record the enter time into map_fun()\n",
    "    map_enter = time.perf_counter()\n",
    "\n",
    "    distorted_image = tf.image.random_flip_left_right(image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "    # ----------------\n",
    "\n",
    "    return tf.concat((steps, tf.tile([[[\"Map\"]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        tf.concat((values, tf.tile([[values[:][-1][0]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        distorted_image,\\\n",
    "        label\n",
    "\n",
    "@map_decorator\n",
    "def map_fun_test_batch(steps, times, values, image, label):\n",
    "    # sleep to avoid concurrency issue\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # record the enter time into map_fun_test()\n",
    "    map_enter = time.perf_counter()\n",
    "\n",
    "    distorted_image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "    # ----------------\n",
    "\n",
    "    return tf.concat((steps, tf.tile([[[\"Map\"]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        tf.concat((values, tf.tile([[values[:][-1][0]]], [BATCH_SIZE, 1, 1])), axis=1),\\\n",
    "        distorted_image,\\\n",
    "        label\n",
    "\n",
    "\n",
    "dataset_train_optimized = tf.data.Dataset.range(1).interleave(dataset_generator_fun_train, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                                                  .shuffle(BUFFER_SIZE)\\\n",
    "                                                  .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "                                                  .map(map_fun_batch, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                                                  .cache('cache')\\\n",
    "                                                  .prefetch(tf.data.AUTOTUNE)\n",
    "dataset_test_optimized = tf.data.Dataset.range(1).interleave(dataset_generator_fun_test, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                                                  .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "                                                  .map(map_fun_test_batch, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                                                  .cache('cache')\\\n",
    "                                                  .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ORitI8ncAZl",
    "outputId": "d7525695-0edb-41f3-ebc5-67cdfc8de0d0"
   },
   "outputs": [],
   "source": [
    "# load the same initialization of weights and re-train with optimized input pipeline\n",
    "wild_model.load_weights('wild_model.weights.h5')\n",
    "timeline_Optimized = timelined_benchmark(dataset_train_optimized, dataset_test_optimized, EPOCHS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "_O0SgDvwqS7M",
    "outputId": "9220f6d6-dfee-4c4c-e73f-c2963c2dedbd"
   },
   "outputs": [],
   "source": [
    "draw_timeline(timeline=timeline_Optimized, title=\"Optimized\", min_width=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5em9uawaqdl"
   },
   "source": [
    "比起單純的data augmentation用時下降不少(3163->571)，map與read都在第1個epoch做完後不重複執行，每個epoch的用時也因平行化下降了許多\n",
    "\n",
    "(train Accuracy,test Accuracy)從(88%,91%)變成(86%,98%)，train accuracy稍微下降，但test accuracy上升不少"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

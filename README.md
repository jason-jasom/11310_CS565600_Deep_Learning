### Predicting News Popularity
In this competition, you are provided with a supervised dataset consisting of the raw content and binary popularity of news articles. What you need to do is to learn a function that is able to predict the popularity of an unseen news article.

### competition2:Object Detection & Localization
In this competition, you should design a model to detect multiple objects in the image. Object detection is a multi-tasks learning problem, which means the model have to localize and classify several objects simultaneously.

### competition3:Reverse Image Caption
In this competition, given a set of texts, your task is to generate suitable imagese to illustrate each of the texts. We will guide you to use GANs to complete this competition.

### lab2:Data Exploration & PCA 
This lab guides you through the process of Exploratory Data Analysis (EDA) and discuss how you can leverage the Principle Component Analysis (PCA) to visualize and understand high-dimensional data.

### lab3:Decision Trees & Random Forest
In this lab, we will apply the Decision Tree and Random Forest algorithms to the classification and dimension reduction problems using the Wine dataset.

### lab4-1:Perceptron & Adaline
In this lab, we will guide you through the implementation of Perceptron and Adaline, two of the first machine learning algorithms for the classification problem. We will also discuss how to train these models using the optimization techniques.

### lab4-2:Regression
This lab guides you through the linear and polynomial regression using the Housing dataset. We will also extend the Decision Tree and Random Forest classifiers to solve the regression problem.

### lab5:Regularization
In this lab, we will guide you through some common regularization techniques such as weight decay, sparse weight, and validation

### lab6:Logistic Regression & Metrics
In this lab, we will guide you through the practice of Logistic Regression. We will also introduce some common evaluation metrics other than the "accuracy" that we have been used so far.

### lab10:Word2Vec
In this lab, we will introduce a neural network, called the word2vec, that embeds words into a dense vector space where semantically similar words are mapped to nearby points.

### lab11-1:Convolutional Neural Networks & Data Pipelines
In this lab, we will introduce two datasets, MNIST and CIFAR-10, then we will talk about how to implement CNN models for these two datasets using tensorflow. Then offer a guide to illustrate typical input pipeline of TensorFlow 2.0.

### lab11-2:Visualization, Style Transfer & Save and Load Models
This lab guides how to load and use a pretrained VGG19 model and how to visualize what the CNN networks have learned in selected layers. This also introduces an interesting technique called "Style Transfer" and displays galleries of its creative outputs. Last but not least, we will also demonstrate how to save and load model during training and explain the TensorFlow family briefly.

### lab12-1:Seq2Seq Learning for Machine Translation
This lab guides how to use recurrent neural networks to model continuous sequence like nature language, and use it on not only article comprehension but also word generation.

### lab12-2:Image Caption
In this lab, we introduce how to design a model that can be given an image, and then generates suitable caption which can describe the image. To accomplish this, you'll use an attention-based model, which enables us to see what parts of the image the model focuses on as it generates a caption.

### lab13-2:Diffusion Models
In this lab, we are going to introduce Diffusion Models.

### lab14:Q-learning
In this lab, we will introduce temporal-difference learning and then use Q-learning to train an agent to play "Flappy Bird" game.

### lab15:PPOxGAE
In this lab, we will introduce PPOxGAE and use it to train a frame-based and state-based agents to play "Flappy Bird" game.